{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4e6c47-e781-4352-a794-9c6a75dfffe6",
   "metadata": {},
   "source": [
    "## 위로봇 오복이 모델 프로세스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da49e66-8312-4efe-b69e-ea0246cf9998",
   "metadata": {},
   "source": [
    "### Base Model Load\n",
    " - 출처 : https://github.com/snunlp/KR-SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74cf3c0-4f04-48cd-b174-12c06c3b7112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df58cc7-bd7e-4844-9d27-67fef45d599b",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f0fe91b-f136-4337-8421-4e7b3e0ad93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/base_datasets.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19eaca1-e42c-4f13-aafb-f7f0b647e41d",
   "metadata": {},
   "source": [
    "### 챗봇 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36efcc8-2ee4-4574-abf0-795033560121",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embeddings = model.encode(\n",
    "    df['user'].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True,\n",
    "    convert_to_numpy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d8b59-1dd8-4bb1-a3ac-5e5d29e5c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"너무 힘들다 요즘\"\n",
    "query_embedding = model.encode(query, normalize_embeddings=True)\n",
    "\n",
    "top_k = min(5, len(df))\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, query_embeddings)[0]\n",
    "top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "print(f\"입력 문장: {query}\")\n",
    "print(f\"<입력 문장과 유사한 {top_k} 개의 문장>\")\n",
    "\n",
    "for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "    print(f\"{i+1}: {df.loc[int(idx)]['system']} {'(유사도: {:.4f})'.format(score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95d6c3-8319-4d51-b656-0d343f688cb5",
   "metadata": {},
   "source": [
    "### Sbert 모델 ONNX 양자화(quantization) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714fec1a-bde8-4153-bfd6-eb0e5c2fdd25",
   "metadata": {},
   "source": [
    "#### Onnx 모델로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d652f672-1a19-4ce9-89ae-f2504c24dcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/convert_graph_to_onnx.py:379: FutureWarning: The `transformers.convert_graph_to_onnx` package is deprecated and will be removed in version 5 of Transformers\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX opset version set to: 11\n",
      "Loading pipeline (model: snunlp/KR-SBERT-V40K-klueNLI-augSTS, tokenizer: snunlp/KR-SBERT-V40K-klueNLI-augSTS)\n",
      "Creating folder onnx_models\n",
      "Using framework PyTorch: 2.0.0\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_1 with shape: {0: 'batch'}\n",
      "Ensuring inputs are in correct order\n",
      "position_ids is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n",
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from transformers.convert_graph_to_onnx import convert\n",
    "convert(framework=\"pt\", model=\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\", output=Path(\"onnx_models/sbert-model.onnx\"), opset=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16681da3-53e5-4b3b-8d5e-f34886f2702e",
   "metadata": {},
   "source": [
    "#### Onnx 모델 Uint8(0~255)로 가중치(Weight) 양자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc76b028-9833-49b3-8233-eda961aea488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[/encoder/layer.0/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.0/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.1/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.1/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.2/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.2/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.3/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.3/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.4/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.4/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.5/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.5/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.6/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.6/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.7/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.7/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.8/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.8/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.9/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.9/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.10/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.10/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.11/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.11/attention/self/MatMul_1]\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "quantize_dynamic(\"onnx_models/sbert-model.onnx\", \"onnx_models/sbert-model_uint8.onnx\", \n",
    "                 weight_type=QuantType.QUInt8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0edd762-e53c-41c0-8313-fb7ee0413c2b",
   "metadata": {},
   "source": [
    "### Onnx 모델로 \"user\"질문 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf01d5b-2910-4b60-a8cd-3f98e3a4736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime import InferenceSession\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "sess = InferenceSession(\"./onnx_models/sbert-model_uint8.onnx\" , providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f49f175-9ac5-42d6-8e6b-b55a6f157a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    model_output = torch.from_numpy(model_output[0])\n",
    "    # First element of model_output contains all token embeddings\n",
    "    token_embeddings = model_output\n",
    "    attention_mask = torch.from_numpy(attention_mask)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(\n",
    "        -1).expand(token_embeddings.size())\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask, input_mask_expanded, sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4a46406-06b6-448c-aa7b-c3b5bb8d6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_query(query: str, normalize_embeddings=False) -> np.ndarray:\n",
    "    # user turn sequence to query embedding\n",
    "    model_inputs = tokenizer(query, return_tensors=\"pt\")\n",
    "    inputs_onnx = {k: v.cpu().detach().numpy()\n",
    "                   for k, v in model_inputs.items()}\n",
    "    sequence = sess.run(None, inputs_onnx)\n",
    "    query_embedding = mean_pooling(\n",
    "        sequence, inputs_onnx[\"attention_mask\"])[0][0]\n",
    "\n",
    "    if normalize_embeddings:\n",
    "        query_embedding = query_embedding / \\\n",
    "            np.linalg.norm(query_embedding)\n",
    "\n",
    "    return query_embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4aedf41-1acf-473b-b748-2197e29acdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 99203/99203 [22:18<00:00, 74.13it/s]\n"
     ]
    }
   ],
   "source": [
    "onnx_embeddings = [ embedding_query(sen, normalize_embeddings=True) for sen in tqdm(df['user'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "148e6e9d-07c6-47f4-a602-d014008c1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"onnx_embeddings.npy\",onnx_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99759726-11f2-45bd-8fa7-e19f592f2a39",
   "metadata": {},
   "source": [
    "### Faiss 벡터 양자화(PQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaefdf89-1fd7-41e5-9599-80742042a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fe8029f-5e4a-4a13-911a-4e47fa1dc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(\"./onnx_embeddings.npy\")\n",
    "\n",
    "# IndexPQ 생성\n",
    "d = embeddings.shape[1]\n",
    "nbits = 8  # 각 부분벡터의 비트 수\n",
    "m = 768  # 분할 수\n",
    "\n",
    "# dot product 거리 측정을 사용하는 벡터 인코더\n",
    "index = faiss.IndexPQ(d, m, nbits, faiss.METRIC_INNER_PRODUCT)  # PQ 색인 생성\n",
    "index.train(embeddings)  # 색인 훈련\n",
    "index.add(embeddings)  # 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3a95605-ff69-4af8-9cbc-8062ab0d1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 저장\n",
    "faiss.write_index(index, \"faiss_onnx_uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945e22a-8928-45a8-a443-2121a5f44914",
   "metadata": {},
   "source": [
    "### 챗봇 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc672623-d030-4da1-8eac-db25a9a526c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reply(query: str):\n",
    "    embedding = np.expand_dims(embedding_query(query, normalize_embeddings=True), axis=0)\n",
    "    D, I = index.search(embedding, 5)\n",
    "    return df.loc[I[0]].system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02d9226f-bcff-4236-9b91-9314e5dcc11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91502                 00님이 제대로 휴식을 취하지 못하고 계신 거 같아 걱정스러워요.\n",
       "90957    피곤해 보여서 걱정이에요. 고른 영양 섭취와 운동 등으로 기초 체력을 길러 보시는 ...\n",
       "88786    피로감이 있으시군요. 잘 쉬는 게 생각보다 참 쉽지 않은 것 같아요. 마음을 조금 ...\n",
       "88240                        피로하면 몸뿐만 아니라 마음도 괴로워지는 거 같아요.\n",
       "17730                        00님이 기운이 없어 보여서 저도 기분이 가라앉아요.\n",
       "Name: system, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply(\"아 너무 힘들다 쉬고 싶어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee413030-13b0-4ed5-be5b-dc8c7e95b6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
